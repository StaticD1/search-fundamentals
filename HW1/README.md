# Краулер

Параллельный краулер на Go. Скачивает HTML-страницы из заданного списка и сохраняет каждую в отдельный файл.

## Запуск

```bash
go mod tidy
go run main.go
```

По умолчанию читает ссылки из `data/urls.txt`. Можно указать другой файл:

```bash
go run main.go path/to/urls.txt
```

## Структура

```
├── main.go
├── go.mod
├── data/
│   └── urls.txt       # ссылки (по одной на строку, # — комментарий)
└── output/            # создаётся автоматически
    ├── 1.txt
    ├── 2.txt
    ├── ...
    └── index.txt      # номер файла → URL
```

## Особенности

- Ссылки группируются по домену — запросы к одному хосту идут последовательно с паузой (защита от 429)
- До 5 доменов качаются параллельно
- Автоматическая перекодировка windows-1251 / KOI8-R → UTF-8
- HTML сохраняется как есть, без очистки от разметки
- В `index.txt` попадают только успешно загруженные страницы
